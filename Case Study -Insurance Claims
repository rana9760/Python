import numpy as np
import pandas as pd
import datetime as dt
import matplotlib.pyplot as plt
import seaborn as sns
import scipy.stats as stats  #for the statistical tests
%matplotlib inline
import plotly.express as px

### 1. Import claims_data.csv and cust_data.csv which is provided to you andmcombine the two datasets appropriately to create a 360-degree view of the data. Use the same for the subsequent questions.

cust_demography = pd.read_csv('C:/Users/ashis/OneDrive/Documents/Data Science 360 Assignment/Python/Case Study 3 - Insurance Claims Case Study/cust_demographics.csv')
claims = pd.read_csv('C:/Users/ashis/OneDrive/Documents/Data Science 360 Assignment/Python/Case Study 3 - Insurance Claims Case Study/claims.csv')

Customer_Claim = pd.merge(left =cust_demography , right = claims , left_on = 'CUST_ID', right_on = 'customer_id'   )
Customer_Claim.head(2)

Customer_Claim.drop(['customer_id','claim_date'],axis = 1,inplace=True)


Customer_Claim.head(2)

### 2 .Perform a data audit for the datatypes and find out if there are any mismatch within the current datatypes of the columns and theirbusiness significance.

Customer_Claim.info()

Customer_Claim.loc [ : , 'DateOfBirth' ] = pd.to_datetime ( Customer_Claim.DateOfBirth , format = '%d/%m/%Y')
Customer_Claim.loc[:,'claim_date_correct'] = pd.to_datetime ( Customer_Claim.claim_date_correct , format = '%d-%m-%Y' )
Customer_Claim['total_policy_claims'] =  Customer_Claim.total_policy_claims.astype(object)

# Customer_Claim['claim_date_correct'] = pd.to_datetime( 'claim_date_correct' , format ="%d/%m/%Y" )

### 3. Convert the column claim_amount to numeric. Use the appropriate modules/attributes to remove the $ sign.

Customer_Claim['claim_amount'] =  Customer_Claim.claim_amount.str.replace('$','').astype(float)

### 4. . Of all the injury claims, some of them have gone unreported with the police. Create an alert flag (1,0) for all such claims.

Customer_Claim.loc[Customer_Claim.police_report == 'Unknown' , 'police_report'] = 1
Customer_Claim.loc[Customer_Claim.police_report == 'No' , 'police_report'] = 0
# Customer_Claim.loc[Customer_Claim.police_report == 'Yes' , 'police_report'] = 2

### 5. One customer can claim for insurance more than once and in each claim, multiple categories of claims can be involved. However, customer ID should remain unique. Retain the most recent observation and delete any duplicated records in the data based on the customer ID column.


Customer_Claim.sort_values(by ='claim_date_correct', ascending = False).drop_duplicates(subset='CUST_ID', keep = 'first')

# We should first sort the data based on the date 
#Customer_Claim.drop_duplicates(subset='CUST_ID', keep = 'first')

Customer_Claim.columns

Customer_Claim.dtypes

# Customer_Claim.duplicated()

# Customer_Claim.loc[:,['CUST_ID','claim_id','Segment','claim_type']]

### 6. Check for missing values and impute the missing values with an appropriate value. (mean for continuous and mode for categorical)


Customer_Claim.isna().sum()

Customer_Claim.loc[Customer_Claim.claim_amount.isna() , 'claim_amount'] = Customer_Claim.claim_amount.mean()

Customer_Claim['total_policy_claims'] = Customer_Claim['total_policy_claims'].fillna(Customer_Claim['total_policy_claims'].mode()[0])

Customer_Claim.isna().sum()

### 7. Calculate the age of customers in years. Based on the age, categorize the customers according to the below criteria
### Children < 18 ; Youth 18-30 ; Adult 30-60 ; Senior > 60


# Customer_Claim.loc [ : , 'DateOfBirth' ] = pd.to_datetime ( Customer_Claim.DateOfBirth , format = '%d/%m/%Y')

# dt.date.today()

Customer_Claim.loc[ : ,'age'] = 2022 - Customer_Claim.DateOfBirth.dt.year

Customer_Claim.loc[ : ,'age_sector'] = pd.Series( np.where( Customer_Claim.age > 60, 'senior', np.where(Customer_Claim.age >= 30 , 'Adult', np.where(Customer_Claim.age >=18 ,'Youth','children')) ) )

### 8. What is the average amount claimed by the customers from various segments?

Customer_Claim.groupby('Segment').claim_amount.sum()

#Customer_Claim.pivot_table(index = 'Segment' ,columns='claim_amount',aggfunc=sum ).T

### 9. What is the total claim amount based on incident cause for all the claims that have been done at least 20 days prior to 1st of October, 2018.

# Customer_Claim.head(2)

# Customer_Claim.incident_cause.unique()

Customer_Claim.loc [Customer_Claim.claim_date_correct > '2018-09-10', ['incident_cause','claim_amount']].groupby('incident_cause').sum('claim_amount')

### 10. How many adults from TX, DE and AK claimed insurance for driver related issues and causes?

Customer_Claim.columns

Customer_Claim.loc[ (Customer_Claim.age_sector == 'Adult') & (Customer_Claim.State.isin(['AK','DE','TX']) ) ,  ['CUST_ID','State'] ].groupby('State').count()

### 11. Draw a pie chart between the aggregated value of claim amount based on gender and segment. Represent the claim amount as a percentage on the pie chart.


Customer_Claim.loc[: , ['gender','Segment','claim_amount']].groupby(['gender','Segment']).sum('claim_amount')

#plt.figlegend(loc ='upper right' )
Customer_Claim.loc[: , ['gender','Segment','claim_amount']].groupby(['gender','Segment']).sum('claim_amount').plot(kind='pie',y='claim_amount',autopct='%1.0f%%')
plt.legend(loc = 'lower right' )
plt.show()

### 12. Among males and females, which gender had claimed the most for any type of driver related issues? E.g. This metric can be compared using a bar chart


# Customer_Claim.head(2)

# Customer_Claim.loc[ Customer_Claim.incident_cause == 'Driver error' , ['CUST_ID','gender'] ].groupby('gender').count()

Customer_Claim.loc[ Customer_Claim.incident_cause == 'Driver error' , ['CUST_ID','gender'] ].groupby('gender').count().plot(kind='bar')
plt.show()

### 13. Which age group had the maximum fraudulent policy claims? Visualize it on a bar chart.

# stores.pivot_table( index = 'Location', columns = 'StoreType', values = 'TotalSales', aggfunc = 'sum' )

# Customer_Claim.pivot_table(index = 'age_sector',columns = 'fraudulent', values = 'CUST_ID' , aggfunc='count')

Customer_Claim.loc[Customer_Claim.fraudulent == 'Yes' ,['CUST_ID','age_sector'] ].groupby('age_sector').count().plot(kind='bar')
plt.show()

#Customer_Claim.groupby(by='age_sector').CUST_ID.count()

### 14. Visualize the monthly trend of the total amount that has been claimed by the customers. Ensure that on the “month” axis, the month is in a chronological order not alphabetical order.

# Customer_Claim.head(2)

# Customer_Claim.loc[:,'claim_date_correct'] = pd.to_datetime ( Customer_Claim.claim_date_correct , format = '%d-%m-%Y' )

#Customer_Claim.groupby (Customer_Claim.claim_date_correct.dt.month).sum('claim_amount')

# Customer_Claim.loc[:  , ['Customer_Claim.claim_date_correct.dt.month','claim_amount']]

Customer_Claim.loc[ : , ['claim_date_correct','claim_amount']].groupby (Customer_Claim.claim_date_correct.dt.month).sum('claim_amount').plot(kind='bar')
plt.show()

### 15. What is the average claim amount for gender and age categories and suitably represent the above using a facetted bar chart, one facet that represents fraudulent claims and the other for non-fraudulent claims.

## NEEDS TO SEEEEEEEEEEEEEEEEEEEEEEEEEEE ..

# Customer_Claim.head(2)

#df_city_grouped.plot(kind='bar',stacked=True,figsize=(9, 6))


# importing packages
# import seaborn
  
# load data
tip = sns.load_dataset('df')
  
# create catplot facetplot object
seaborn_facetgrid_object = seaborn.catplot(
    x='age_sector',
    y='claim_amount',
    col='fraudulent',
    kind='bar',
    data=tip
)
# show plot
seaborn_facetgrid_object

sns.FacetGrid()

Customer_Claim.loc[ : , ['fraudulent','gender','age_sector','claim_amount']].groupby( ['fraudulent','gender','age_sector'] ).mean('claim_amount').plot(kind='bar',stacked=True,figsize=(9, 6))
plt.show()

#Customer_Claim.loc[: , ['fraudulent','gender','age_sector','claim_amount']].groupby( ['fraudulent','gender','age_sector'] ).sum('claim_amount').plot(kind='bar',figsize=(9, 6))
#plt.show()

df = Customer_Claim.loc[: , ['fraudulent','gender','age_sector','claim_amount']].groupby( ['fraudulent','gender','age_sector'] ).mean('claim_amount')
df

#Customer_Claim.loc[Customer_Claim.fraudulent=='No' , ['gender','age_sector','claim_amount']].groupby( ['gender','age_sector'] ).sum('claim_amount')

#Customer_Claim.loc[Customer_Claim.fraudulent=='Yes' , ['gender','age_sector','claim_amount']].groupby( ['gender','age_sector'] ).sum('claim_amount')

### Based on the conclusions from exploratory analysis as well as suitable statistical tests, answer the below questions. Please include a detailed write-up on the parameters taken into consideration, the Hypothesis testing steps, conclusion from the p-values and the business implications of the statements.

### 16. Is there any similarity in the amount claimed by males and females?

Customer_Claim.columns

# Customer_Claim.loc[:  , ['gender', 'claim_amount']]

# Customer_Claim.loc[:  , ['gender', 'claim_amount']].groupby('gender').sum()

Male_Claim = Customer_Claim.loc[ Customer_Claim.gender == 'Male' , 'claim_amount']
Female_Claim = Customer_Claim.loc[ Customer_Claim.gender == 'Female' , 'claim_amount']


# display the mean of both gender
print('mean of Male gender :', Male_Claim.mean() , '| mean of Female_gender :',Female_Claim.mean() )

#stats.ttest_ind( Male_Claim , Female_Claim )

# Step 0 : All the samples are from same population , mean are equal
# Step 1 : Samples are from different population , mean are unequal 
# Step 3 : CI = 95% , p = 0.05
# Step 4 : Perform the ANOVA Test 
stats.f_oneway( Male_Claim , Female_Claim )

# Step 5 : Conclusion : We fail to reject Null Hypothesis.. 

# Step 6 : Business Conclusion :
# Both Male & Female have similarity in the amount claimed



### 17. Is there any relationship between age category and segment?

Customer_Claim.Segment.unique()

Customer_Claim.claim_type.unique()

# get the observed_frequency_table fro the dataset
obs_freq = pd.crosstab(Customer_Claim.age_sector , Customer_Claim.Segment)
obs_freq

# Step 0 : Define Null Hypothesis (Ho) : No relationship
# Step 1 : Ha : Association
# Step 2 : CI: 95% , p =0.05
# Step 3 : perforn the test
stats.chi2_contingency(obs_freq)

# Step 4 : Conclusion : We fail to reject null Hypothesis ..

# Step 5 : Business Conclusion
# we have different age group customer & they are claiming for different Segment ..

### 18. The current year has shown a significant rise in claim amounts as compared to 2016-17 fiscal average which was $10,000

#Customer_Claim.claim_date_correct

#Customer_Claim.head(2)

pop_mean = 10000
sample = Customer_Claim.loc[ Customer_Claim.claim_date_correct.dt.year > 2017 , 'claim_amount']
sample_mean = sample.mean() 

# display the means
print('Mean of 2016-2017 fiscal year :',pop_mean,  '| Mean of 2017-2018 fiscal year :' ,sample_mean )

#Customer_Claim.isna().sum()

# H0: u <= 50
# Ha: u > 50
# CI: 99%, p: 0.01

# perform the test
stats.ttest_1samp( a = sample, popmean = pop_mean , nan_policy = 'omit' )

# Conclusion : We are rejecting the null Hypothesis with 99% of CI

# Business conclusion:
# Claim amount  has increased from the last year hypothysed value of 50

### 19. Is there any difference between age groups and insurance claims?


obs_freq = pd.crosstab(Customer_Claim.age_sector , Customer_Claim.total_policy_claims)
obs_freq

# Step 0 : Define Null Hypothesis (Ho) : No relationship
# Step 1 : Ha : Association
# Step 2 : CI: 95% , p =0.05
# Step 3 : perforn the test
stats.chi2_contingency(obs_freq)

# Step 4 : Conclusion : We fail to reject null Hypothesis with CI of 95% even 99% ..

# Step 5 : Business Conclusion 
# we have different age groups & they are claiming differently
# Adults are claims more as compare to other age group . 

### 20. Is there any relationship between total number of policy claims and the claimed amount?

Customer_Claim.plot( kind = 'scatter', x = 'total_policy_claims', y = 'claim_amount' )
plt.show() # w/o plt.show() it will give in a form of O/p ..

Customer_Claim.loc[: , ['claim_amount','total_policy_claims']].corr()

# Ho: No relationship
# Ha: Association
# CI: 95%, p: 0.05

# perform the test 
stats.pearsonr( Customer_Claim.total_policy_claims ,  Customer_Claim.claim_amount  )

# conclusion: We fail to reject Null Hypothesis.
# There is a very  weak relationsip between total_policy_claims and claim_amount , it's indirect relationship.

# Business conclusion
# we have customer it's not claiming more policy .
# we can say that as the we have less number of sum of claim_amount when we have total_policy claims more ..

